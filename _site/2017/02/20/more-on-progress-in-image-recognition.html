<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>More On Image Recognition Progress | Sarah Constantin</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="More On Image Recognition Progress" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="In my post on AI progress, I picked a few benchmark tasks, to see how machine learning algorithms have improved over the past few decades. Obviously those aren’t a comprehensive list, so I thought I’d add a few more." />
<meta property="og:description" content="In my post on AI progress, I picked a few benchmark tasks, to see how machine learning algorithms have improved over the past few decades. Obviously those aren’t a comprehensive list, so I thought I’d add a few more." />
<link rel="canonical" href="https://srconstantin.github.io/2017/02/20/more-on-progress-in-image-recognition.html" />
<meta property="og:url" content="https://srconstantin.github.io/2017/02/20/more-on-progress-in-image-recognition.html" />
<meta property="og:site_name" content="Sarah Constantin" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2017-02-20T00:00:00-07:00" />
<script type="application/ld+json">
{"description":"In my post on AI progress, I picked a few benchmark tasks, to see how machine learning algorithms have improved over the past few decades. Obviously those aren’t a comprehensive list, so I thought I’d add a few more.","@type":"BlogPosting","url":"https://srconstantin.github.io/2017/02/20/more-on-progress-in-image-recognition.html","headline":"More On Image Recognition Progress","dateModified":"2017-02-20T00:00:00-07:00","datePublished":"2017-02-20T00:00:00-07:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://srconstantin.github.io/2017/02/20/more-on-progress-in-image-recognition.html"},"@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/main.css"><link type="application/atom+xml" rel="alternate" href="https://srconstantin.github.io/feed.xml" title="Sarah Constantin" />
  









<a class="btn btn-rss" href="/feed.xml" target="_blank">RSS</a>

<link rel="alternate" type="application/atom+xml" title="Sarah Constantin's Blog" href="/feed.xml">
</head>
<body><header class="site-header" role="banner">

  <div class="wrapper"><a class="site-title" rel="author" href="/">Sarah Constantin</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/about/">About</a><a class="page-link" href="/tag/aging.html">Aging</a><a class="page-link" href="/tag/blog-meta.html">Blog Meta</a><a class="page-link" href="/tag/book-review.html">Book Reviews</a><a class="page-link" href="/tag/business.html">Business</a><a class="page-link" href="/tag/cancer.html">Cancer</a><a class="page-link" href="/tag/cog-psych.html">Cognition &amp; Psychology</a><a class="page-link" href="/tag/covid-19.html">COVID-19</a><a class="page-link" href="/tag/econ.html">Economics</a><a class="page-link" href="/tag/game-theory.html">Game Theory</a><a class="page-link" href="/tag/lit-review.html">Literature Review</a><a class="page-link" href="/tag/machine-learning.html">Machine Learning</a><a class="page-link" href="/tag/medicine.html">Medicine</a><a class="page-link" href="/tag/personal.html">Personal</a><a class="page-link" href="/tag/philanthropy.html">Philanthropy</a><a class="page-link" href="/tag/science-and-epistemics.html">Science &amp; Epistemics</a><a class="page-link" href="/tag/social.html">Social Dynamics</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">More On Image Recognition Progress</h1>
    <p class="post-meta">
      <time class="dt-published" datetime="2017-02-20T00:00:00-07:00" itemprop="datePublished">Feb 20, 2017
      </time></p>
  </header>

  <div class="post-content e-content" itemprop="articleBody">
    
<ul class="tags">
  
  <li>
    <a href="/tag/machine-learning"></a>
  </li>
</ul><br>


<article>
  <p>In my post on <a href="https://srconstantin.wordpress.com/2017/01/28/performance-trends-in-ai/">AI progress</a>, I picked a few benchmark tasks, to see how machine learning algorithms have improved over the past few decades. Obviously those aren’t a comprehensive list, so I thought I’d add a few more.</p>

<p>I also claimed in that post that image recognition was “slowing down”, because the rate of improvement in accuracy percent was diminishing. I’ve since been convinced that a more meaningful metric for performance in image classification (or any classification task where perfect accuracy means 100% correct) is the negative log of the error rate. Obviously, as we approach perfect classification, no matter how quickly we do so, the raw percent accuracy score must “flatten out” because it’s bounded above by 100%. Transforming it into a log scale means that an error that decayed exponentially to zero over time would look like “linear progress”, which seems more natural. “Linear progress” on a log scale, given a continuation of Moore’s law, also means something like <em>linear returns to computing power</em> — i.e. scaling and parallelization don’t present much in the way of an impediment.</p>

<p>From this <a href="http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html">dataset</a>, I found (crowdsourced) papers and dates for performance on six image recognition benchmarks datasets, and graphed -log(error) over time.</p>

<p><img src="/images/CIFAR-10.png" alt="CIFAR-10" /></p>

<p><img src="/images/CIFAR-100.png" alt="CIFAR-100" /></p>

<p><img src="/images/SHVN.png" alt="SHVN" /></p>

<p><img src="/images/STL-10.png" alt="STL-10" /></p>

<p><img src="/images/MNIST.png" alt="MNIST" /></p>

<p>With the possible exception of MNIST, all of these show a positive trend over time, and some are clearly linear. Most of these data points come from deep learning algorithms, except a few of the very earliest ones.</p>

<p>For reference, here’s the ImageNet performance data from the past post, but transformed to -log(error) instead of accuracy percent. It, too, looks linear.</p>

<p><img src="/images/ImageNet.png" alt="ImageNet" /></p>

<p>The picture here looks quite similar to the performance over time of AI at chess and go, which looks roughly linear in Elo score (also a measure that is roughly logarithmic in the “raw” percent of games won.)  Progress since the advent of deep learning has been steady. Returns to computing power appear roughly linear in Elo score, and also roughly linear in -log(error).</p>

<p>What does this mean, as a bottom line for the future of AI?</p>

<p>In those areas where deep learning can be successful, it seems like scaling is not an insurmountable problem: if you put more computational resources in, you can get more performance out.  The curve’s not going to bend <em>upward</em> — deep learning algorithms don’t get smarter per GPU if you add more GPU’s — but, at least for the past few years, marginal returns to GPUs and training data have been more or less constant, not falling.  “Just do exactly what you’re doing, but more so” should yield steady improvements in narrow AI performance, at least for a while.</p>

</article>


  </div><a class="u-url" href="/2017/02/20/more-on-progress-in-image-recognition.html" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <h2 class="footer-heading">Sarah Constantin</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="p-name">Sarah Constantin</li><li><a class="u-email" href="mailto:srconstantin@gmail.com">srconstantin@gmail.com</a></li></ul>
      </div>

      <div class="footer-col footer-col-2"><ul class="social-media-list"><li><a href="https://github.com/srconstantin"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg> <span class="username">srconstantin</span></a></li><li><a href="https://www.twitter.com/s_r_constantin"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#twitter"></use></svg> <span class="username">s_r_constantin</span></a></li></ul>
</div>

      <div class="footer-col footer-col-3">
        <p>Trained in math and machine learning, currently trying to solve technological problems and make sense of our world.</p>
      </div>
    </div>

  </div>

</footer>
</body>

</html>
